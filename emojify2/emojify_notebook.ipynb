{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7badec",
   "metadata": {},
   "source": [
    "<h1> Emojify! </h1>\n",
    "\n",
    "<h2> Input: where is the food </h2>\n",
    "\n",
    "<h2> Output: where is the food üç¥</h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p> 1. We'll use the <b>emoji</b> package to help display emoticons.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce18ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install emoji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b05998",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 2. Import relevant libraries. The <b>emo_utils</b> library has some useful functions for this exercise, such as mapping integers to emoticons. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad731dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbcbc3a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 3. Using <b>label_to_emoji(idx)</b> to map integers to emoticons. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e216b9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t ‚ù§Ô∏è \n",
      "\n",
      "1 \t ‚öæ \n",
      "\n",
      "2 \t üòÑ \n",
      "\n",
      "3 \t :disappointed: \n",
      "\n",
      "4 \t üç¥ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    print(idx,'\\t',label_to_emoji(idx),'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6ee6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 4. <b>train.csv</b> contains some training sentences. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3781a231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 2) \n",
      "\n",
      "never talk to me again 3 :disappointed:\n",
      "I am proud of your achievements 2 üòÑ\n",
      "It is the worst day in my life 3 :disappointed:\n",
      "Miss you so much 0 ‚ù§Ô∏è\n",
      "food is life 4 üç¥\n",
      "I love you mum 0 ‚ù§Ô∏è\n",
      "Stop saying bullshit 3 :disappointed:\n",
      "congratulations on your acceptance 2 üòÑ\n",
      "The assignment is too long 3 :disappointed:\n",
      "I want to go play 1 ‚öæ\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array(pd.read_csv('train.csv', header=None, index_col=False))\n",
    "print(train_data.shape,'\\n')\n",
    "\n",
    "X_train, Y_train = train_data[:,0], train_data[:,1]\n",
    "Y_train = np.array(Y_train, dtype=int)\n",
    "\n",
    "for idx in range(10):\n",
    "    print(X_train[idx], Y_train[idx], label_to_emoji(Y_train[idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b8018",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 5. <b>test.csv</b> contains some test sentences. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627d35cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 2)\n",
      "I want to eat 4 üç¥\n",
      "he did not answer 3 :disappointed:\n",
      "he got a very nice raise 2 üòÑ\n",
      "she got me a nice present 2 üòÑ\n",
      "ha ha ha it was so funny 2 üòÑ\n",
      "he is a good friend 2 üòÑ\n",
      "I am upset 3 :disappointed:\n",
      "We had such a lovely dinner tonight 2 üòÑ\n",
      "where is the food 4 üç¥\n",
      "Stop making this joke ha ha ha 2 üòÑ\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array(pd.read_csv('test.csv', header=None, index_col=False))\n",
    "print(test_data.shape)\n",
    "\n",
    "X_test, Y_test = test_data[:,0], test_data[:,1]\n",
    "Y_test = np.array(Y_test, dtype=int)\n",
    "\n",
    "for idx in range(10):\n",
    "    print(X_test[idx], Y_test[idx], label_to_emoji(Y_test[idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e92917",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "6. <b>glove.6B.50d.txt</b> contains 50-dimensional GloVe embeddings for some common english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67eae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632bd157",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 7. An example of mapping a word to its unique index, and obtaining its GloVe embedding. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01ec8e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is: 113317 \n",
      "\n",
      "GloVe of cucumber is:\n",
      " [ 0.68224  -0.31608  -0.95201   0.47108   0.56571   0.13151   0.22457\n",
      "  0.094995 -1.3237   -0.51545  -0.39337   0.88488   0.93826   0.22931\n",
      "  0.088624 -0.53908   0.23396   0.73245  -0.019123 -0.26552  -0.40433\n",
      " -1.5832    1.1316    0.4419   -0.48218   0.4828    0.14938   1.1245\n",
      "  1.0159   -0.50213   0.83831  -0.31303   0.083242  1.7161    0.15024\n",
      "  1.0324   -1.5005    0.62348   0.54508  -0.88484   0.53279  -0.085119\n",
      "  0.02141  -0.56629   1.1463    0.6464    0.78318  -0.067662  0.22884\n",
      " -0.042453]\n",
      "\n",
      "the 289845th word in the vocabulary is potatoes\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "print(\"the index of\", word, \"in the vocabulary is:\", word_to_index[word],'\\n')\n",
    "print('GloVe of', word, \"is:\\n\", word_to_vec_map[word])\n",
    "\n",
    "index = 289845\n",
    "print(\"\\nthe\", str(index) + \"th word in the vocabulary is\", index_to_word[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca25ae1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 8. Create a dataset to train in PyTorch. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76fb80ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([259914., 352214., 360915., 239105.,  47887.,      0.,      0.,\n",
      "            0.,      0.,      0.]), 3)\n"
     ]
    }
   ],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    for i in range(m):\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            X_indices[i, j] = int(word_to_index[w])\n",
    "            j = j + 1\n",
    "    return X_indices\n",
    "\n",
    "\n",
    "class emojiDataset(Data.Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train\n",
    "        traindata,trainlabels = read_csv(os.path.join(self.root,'train.csv'))\n",
    "        self.train_data = sentences_to_indices(traindata, word_to_index, 10)\n",
    "        self.train_labels = trainlabels\n",
    "        # self.train_labels = convert_to_one_hot(trainlabels, C=5)\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            data, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            pass\n",
    "        if self.transform is not None:\n",
    "            pass\n",
    "        if self.target_transform is not None:\n",
    "            pass\n",
    "        return data, target\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return 132\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "train_data = emojiDataset(\n",
    "    root='./',\n",
    ")\n",
    "print(train_data[0])\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=20, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alive-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10]) torch.Size([20])\n",
      "tensor([[386887., 192973., 394565., 145839., 286410.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457., 246253., 178965.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [175199., 192973., 218178.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [175199., 192973., 172650.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [386887., 192973., 128527., 151349.,  43010., 306601.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [155345.,      0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [193716., 192973., 357266., 390080., 117874., 188481., 254258., 222138.,\n",
      "              0.,      0.],\n",
      "        [327864., 192973., 336114., 114194.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [394475.,  58997.,  43010., 225947.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [386307.,  43010., 155185., 248238.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [259914., 352214., 360915., 239105.,  47887.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457.,  52943., 293982., 268046., 394565.,  45460.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [343812., 319745.,  86650.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457., 222471., 394475.,  43010., 225985.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457., 315709., 393658.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457., 383068., 360915., 174642., 348681., 151349., 124461.,      0.,\n",
      "              0.,      0.],\n",
      "        [358160., 192973.,  65963.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [361940.,  65963., 357212., 394475., 385664., 264550., 177231.,      0.,\n",
      "              0.,      0.],\n",
      "        [182540., 117064., 394475.,  61257., 357212.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457.,  52943., 336114., 188347.,  88126., 394565., 119051., 360915.,\n",
      "         358160., 293229.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    t, l = data\n",
    "    print(t.shape, l.shape)\n",
    "    print(t)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b406a8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 9. Create an embedding layer to obtain GloVe embeddings. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2887abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400001, 50)\n"
     ]
    }
   ],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1  #word index begin with 1,plus 1 for padding 0\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "    return emb_matrix\n",
    "\n",
    "emb_matrix = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(emb_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e54ca",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 10. Define the network: </p>\n",
    "\n",
    "<img src=\"img_lstm_network.png\">\n",
    "\n",
    "<p> (image source: https://github.com/Kulbear/deep-learning-coursera) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "productive-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0456,  0.0400, -0.0287,  0.0486,  0.0808,  0.0139, -0.0023,\n",
       "           0.0540, -0.0258, -0.0306, -0.0697, -0.0127,  0.0282, -0.0416,\n",
       "           0.0286, -0.0392, -0.0074, -0.0090,  0.0190,  0.0245],\n",
       "         [ 0.0360,  0.0308, -0.0412,  0.0305,  0.0790,  0.0094, -0.0038,\n",
       "           0.0538, -0.0226, -0.0320, -0.0965, -0.0250,  0.0446, -0.0489,\n",
       "           0.0271, -0.0214,  0.0126, -0.0076,  0.0214,  0.0421],\n",
       "         [ 0.0333,  0.0235, -0.0288,  0.0410,  0.0756,  0.0294, -0.0090,\n",
       "           0.0556, -0.0365, -0.0417, -0.1009, -0.0236,  0.0406, -0.0315,\n",
       "           0.0326, -0.0344,  0.0195, -0.0057,  0.0587,  0.0280]],\n",
       "\n",
       "        [[ 0.0271,  0.0627, -0.0507,  0.0860,  0.1154, -0.0021, -0.0015,\n",
       "           0.1279, -0.0283, -0.0380, -0.1329, -0.0318,  0.0208, -0.0291,\n",
       "           0.0294, -0.0335,  0.0037, -0.0295,  0.0064,  0.0531],\n",
       "         [ 0.0412,  0.0430, -0.0409,  0.0355,  0.1105,  0.0459, -0.0017,\n",
       "           0.0938, -0.0373, -0.0605, -0.1290, -0.0378,  0.0568, -0.0552,\n",
       "           0.0484, -0.0398,  0.0257, -0.0087,  0.0692,  0.0540],\n",
       "         [ 0.0299,  0.0488, -0.0284,  0.0766,  0.1069,  0.0595,  0.0038,\n",
       "           0.1025, -0.0435, -0.0707, -0.1378, -0.0360,  0.0309, -0.0204,\n",
       "           0.0415, -0.0493,  0.0260, -0.0128,  0.0846,  0.0480]],\n",
       "\n",
       "        [[ 0.0391,  0.0846, -0.0567,  0.0827,  0.1250,  0.0016,  0.0123,\n",
       "           0.1494, -0.0538, -0.0568, -0.1478, -0.0315,  0.0318, -0.0399,\n",
       "           0.0415, -0.0389,  0.0111, -0.0310,  0.0123,  0.0658],\n",
       "         [ 0.0416,  0.0589, -0.0378,  0.0462,  0.1172,  0.0512,  0.0065,\n",
       "           0.1287, -0.0555, -0.0844, -0.1473, -0.0474,  0.0381, -0.0446,\n",
       "           0.0588, -0.0452,  0.0326, -0.0279,  0.0816,  0.0669],\n",
       "         [ 0.0262,  0.0719, -0.0133,  0.1114,  0.1130,  0.1036,  0.0238,\n",
       "           0.1276, -0.0463, -0.0950, -0.1456, -0.0325,  0.0245,  0.0065,\n",
       "           0.0417, -0.0647,  0.0255, -0.0245,  0.1131,  0.0634]],\n",
       "\n",
       "        [[ 0.0393,  0.0867, -0.0320,  0.0830,  0.1421,  0.0344,  0.0301,\n",
       "           0.1459, -0.0353, -0.0713, -0.1225, -0.0214,  0.0457, -0.0252,\n",
       "           0.0569, -0.0628,  0.0044, -0.0221,  0.0445,  0.0554],\n",
       "         [ 0.0450,  0.0788, -0.0243,  0.0570,  0.1208,  0.0305,  0.0153,\n",
       "           0.1494, -0.0665, -0.0943, -0.1453, -0.0410,  0.0233, -0.0425,\n",
       "           0.0713, -0.0580,  0.0266, -0.0309,  0.0638,  0.0697],\n",
       "         [ 0.0206,  0.0673, -0.0213,  0.0777,  0.1055,  0.0923,  0.0278,\n",
       "           0.1324, -0.0343, -0.0966, -0.1744, -0.0552,  0.0383, -0.0012,\n",
       "           0.0443, -0.0330,  0.0229, -0.0322,  0.1036,  0.1040]],\n",
       "\n",
       "        [[ 0.0386,  0.0751, -0.0414,  0.0586,  0.1487,  0.0437,  0.0345,\n",
       "           0.1212, -0.0393, -0.0689, -0.1663, -0.0428,  0.0926, -0.0362,\n",
       "           0.0600, -0.0398, -0.0028, -0.0119,  0.0608,  0.0664],\n",
       "         [ 0.0637,  0.0882, -0.0239,  0.0513,  0.1143,  0.0591,  0.0268,\n",
       "           0.1450, -0.0693, -0.1009, -0.1439, -0.0346,  0.0337, -0.0463,\n",
       "           0.0631, -0.0426,  0.0290, -0.0321,  0.0773,  0.0908],\n",
       "         [ 0.0232,  0.0760, -0.0211,  0.0754,  0.1155,  0.0837,  0.0324,\n",
       "           0.1411, -0.0297, -0.0948, -0.1526, -0.0509,  0.0336, -0.0033,\n",
       "           0.0483, -0.0305, -0.0008, -0.0307,  0.0792,  0.1018]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "output = rnn(input)\n",
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cognitive-albert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNN(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "output = rnn(input)\n",
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "worth-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.GRU(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "output = rnn(input)\n",
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ad5177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,pretrained_weight):\n",
    "        super(myModel,self).__init__()\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        pretrained_weight = np.array(pretrained_weight)\n",
    "        self.word_embeds.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, 128, 2,batch_first=True,dropout=0.5)\n",
    "        self.linear = nn.Linear(128,5)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.word_embeds(x)\n",
    "        out, _ = self.rnn(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.linear(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20136d04",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 11. Create the network: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b8a048a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (word_embeds): Embedding(400001, 50)\n",
       "  (rnn): LSTM(50, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(word_to_index) + 1\n",
    "model = myModel(vocab_len,50,emb_matrix)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2242ac89",
   "metadata": {},
   "source": [
    "<p> 12. Define the loss function and the optimizers. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08713e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer1 = torch.optim.Adam(model.rnn.parameters(),lr=0.001)\n",
    "optimizer2 = torch.optim.Adam(model.linear.parameters(),lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-cooling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dab50dc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 13. Start the training process.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "989bf7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss: 11.26416277885437\n",
      "epoch:  10 loss: 9.732757687568665\n",
      "epoch:  20 loss: 8.522547602653503\n",
      "epoch:  30 loss: 7.745697259902954\n",
      "epoch:  40 loss: 6.840422987937927\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for step,(data,target) in enumerate(train_loader):\n",
    "        data = data.long()\n",
    "        target = target.long()\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        input = Variable(data).to(device)\n",
    "        target = Variable(target).to(device)\n",
    "        output = model(input)\n",
    "        \n",
    "        loss = loss_func(output,target)\n",
    "        \n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "        print('epoch: ', epoch, 'loss:', total_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0668212",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 14. Test the trained network. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ceeb69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " prediction: I want to eatüç¥\n",
      " prediction: he did not answer:disappointed:\n",
      " prediction: he got a very nice raiseüç¥\n",
      " prediction: she got me a nice present‚ù§Ô∏è\n",
      " prediction: ha ha ha it was so funnyüòÑ\n",
      " prediction: he is a good friendüòÑ\n",
      " prediction: I am upsetüòÑ\n",
      " prediction: We had such a lovely dinner tonightüç¥\n",
      " prediction: where is the foodüç¥\n",
      " prediction: Stop making this joke ha ha haüòÑ\n",
      " prediction: where is the ball‚öæ\n",
      " prediction: work is hardüòÑ\n",
      " prediction: This girl is messing with me:disappointed:\n",
      " prediction: are you serious:disappointed:\n",
      " prediction: Let us go play baseball‚öæ\n",
      " prediction: This stupid grader is not working:disappointed:\n",
      " prediction: work is horribleüòÑ\n",
      " prediction: Congratulation for having a babyüòÑ\n",
      " prediction: stop pissing me off:disappointed:\n",
      " prediction: any suggestions for dinnerüòÑ\n",
      " prediction: I love taking breaks:disappointed:\n",
      " prediction: you brighten my day:disappointed:\n",
      " prediction: I boiled riceüç¥\n",
      " prediction: she is a bully‚ù§Ô∏è\n",
      " prediction: Why are you feeling bad:disappointed:\n",
      " prediction: I am upsetüòÑ\n",
      " prediction: give me the ball‚öæ\n",
      " prediction: My grandmother is the love of my life‚ù§Ô∏è\n",
      " prediction: enjoy your game‚öæ\n",
      " prediction: valentine day is nearüç¥\n",
      " prediction: I miss you so much‚ù§Ô∏è\n",
      " prediction: throw the ball‚öæ\n",
      " prediction: My life is so boring:disappointed:\n",
      " prediction: she said yesüòÑ\n",
      " prediction: will you be my valentine:disappointed:\n",
      " prediction: he can pitch really well‚öæ\n",
      " prediction: dance with meüòÑ\n",
      " prediction: I am hungryüòÑ\n",
      " prediction: See you at the restaurantüç¥\n",
      " prediction: I like to laughüòÑ\n",
      " prediction: I will run‚öæ\n",
      " prediction: I like your jacket‚ù§Ô∏è\n",
      " prediction: i miss her‚ù§Ô∏è\n",
      " prediction: what is your favorite baseball game‚öæ\n",
      " prediction: Good jobüòÑ\n",
      " prediction: I love you to the stars and back‚öæ\n",
      " prediction: What you did was awesome:disappointed:\n",
      " prediction: ha ha ha lolüòÑ\n",
      " prediction: I do not want to joke:disappointed:\n",
      " prediction: go away:disappointed:\n",
      " prediction: yesterday we lost again:disappointed:\n",
      " prediction: family is all I have‚ù§Ô∏è\n",
      " prediction: you are failing this exercise:disappointed:\n",
      " prediction: Good jokeüòÑ\n",
      " prediction: You deserve this nice prizeüòÑ\n",
      " prediction: I did not have breakfastüç¥\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, 10)\n",
    "X_test_indices = torch.from_numpy(X_test_indices)\n",
    "X_test_indices = Variable(X_test_indices.long()).to(device)\n",
    "pred = model(X_test_indices)\n",
    "num = np.zeros((X_test.shape[0]), dtype=int)\n",
    "for i in range(len(X_test)):\n",
    "    num[i] = np.argmax(pred.data[i].detach().cpu().numpy())\n",
    "    print(' prediction: ' + X_test[i] + label_to_emoji(num[i]).strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b159649",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 15. Contingency Matrix of class-wise accuracy </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8e6806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ‚ù§Ô∏è    ‚öæ    üòÑ    :disappointed:   üç¥\n",
      "Predicted  0  1   2   3  4  All\n",
      "Actual                         \n",
      "0          5  1   0   1  0    7\n",
      "1          0  8   0   0  0    8\n",
      "2          1  0  11   3  3   18\n",
      "3          1  0   4  11  0   16\n",
      "4          0  0   2   0  5    7\n",
      "All        7  9  17  15  8   56\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, num.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a81c633",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "References:\n",
    "\n",
    "https://github.com/Kulbear/deep-learning-coursera\n",
    "\n",
    "https://github.com/sushantdhumak/Emojify\n",
    "\n",
    "https://github.com/cryer/emojify-pyTorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
